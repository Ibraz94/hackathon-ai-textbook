"use strict";(globalThis.webpackChunkdocusaurus_site=globalThis.webpackChunkdocusaurus_site||[]).push([[7648],{5058:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"hardware-context","title":"Hardware Context","description":"This section outlines the key hardware components recommended or required for engaging with the practical exercises and examples throughout the course. While cloud-based and virtual solutions are often prioritized for accessibility, understanding the physical hardware context is crucial for embodied AI.","source":"@site/docs/hardware-context.mdx","sourceDirName":".","slug":"/hardware-context","permalink":"/physical-ai-textbook/docs/next/hardware-context","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/hardware-context.mdx","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"Hardware Context"},"sidebar":"modulesSidebar","previous":{"title":"Module 4: Vision-Language-Action (VLA)","permalink":"/physical-ai-textbook/docs/next/modules/vla"},"next":{"title":"Constitution","permalink":"/physical-ai-textbook/docs/next/constitution"}}');var t=n(4848),r=n(8453);const o={sidebar_position:5,title:"Hardware Context"},a="Hardware Context: Essential Components for Robotics AI",c={},l=[{value:"1. NVIDIA RTX GPUs",id:"1-nvidia-rtx-gpus",level:2},{value:"2. NVIDIA Jetson Kits",id:"2-nvidia-jetson-kits",level:2},{value:"3. RealSense D435i Sensor",id:"3-realsense-d435i-sensor",level:2},{value:"Cloud-First Approach for Accessibility",id:"cloud-first-approach-for-accessibility",level:2}];function d(e){const i={h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.header,{children:(0,t.jsx)(i.h1,{id:"hardware-context-essential-components-for-robotics-ai",children:"Hardware Context: Essential Components for Robotics AI"})}),"\n",(0,t.jsx)(i.p,{children:"This section outlines the key hardware components recommended or required for engaging with the practical exercises and examples throughout the course. While cloud-based and virtual solutions are often prioritized for accessibility, understanding the physical hardware context is crucial for embodied AI."}),"\n",(0,t.jsx)(i.h2,{id:"1-nvidia-rtx-gpus",children:"1. NVIDIA RTX GPUs"}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Role"}),": Essential for high-performance computing, especially for AI-intensive simulations, deep learning model training, and real-time inference. Many of the NVIDIA Isaac Sim environments and LLM-integrated robotics tasks benefit significantly from the parallel processing capabilities of RTX GPUs."]}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Specific References"}),": RTX 30 Series (e.g., 3080, 3090) or RTX 40 Series (e.g., 4080, 4090)."]}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Cloud/Virtual Access"}),": Cloud instances offering NVIDIA GPUs (e.g., AWS EC2 P- or G-series, Google Cloud A2 instances) are highly recommended alternatives for students without access to local RTX GPUs."]}),"\n",(0,t.jsx)(i.h2,{id:"2-nvidia-jetson-kits",children:"2. NVIDIA Jetson Kits"}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Role"}),": These powerful, small-form-factor System-on-Modules (SOMs) are designed for AI at the edge. They are crucial for deploying and testing AI models directly on robotic platforms, enabling real-time inference and embedded intelligence."]}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Specific References"}),":"]}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"NVIDIA Jetson Orin Nano"}),": An entry-level yet powerful option for a wide range of AI and robotics applications."]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"NVIDIA Jetson AGX Xavier"}),": A higher-performance option for more demanding AI workloads and complex robotic systems."]}),"\n"]}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Cloud/Virtual Access"}),": While physical Jetson kits are ideal for deployment, students can utilize Jetson emulators (e.g., within NVIDIA SDK Manager) or cloud services offering virtual Jetson environments for initial development and testing."]}),"\n",(0,t.jsx)(i.h2,{id:"3-realsense-d435i-sensor",children:"3. RealSense D435i Sensor"}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Role"}),": A versatile depth-sensing camera from Intel, critical for tasks requiring depth perception, 3D reconstruction, and visual navigation (e.g., VSLAM). Its integrated IMU (Inertial Measurement Unit) is valuable for precise robot localization and mapping."]}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Specific References"}),": Intel RealSense D435i (or equivalent depth camera with integrated IMU capabilities)."]}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Cloud/Virtual Access"}),": For simulation-based exercises, virtual sensors within environments like Gazebo or NVIDIA Isaac Sim can emulate the D435i's output, abstracting the need for the physical sensor."]}),"\n",(0,t.jsx)(i.h2,{id:"cloud-first-approach-for-accessibility",children:"Cloud-First Approach for Accessibility"}),"\n",(0,t.jsx)(i.p,{children:"As clarified in the specification, cloud instances or virtual machines will be prioritized for hardware access where feasible. This approach aims to abstract away the necessity of owning specific physical hardware for many practical exercises, making the course more accessible. Students are encouraged to explore cloud provider offerings that meet the computational requirements outlined for each component."})]})}function h(e={}){const{wrapper:i}={...(0,r.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,i,n)=>{n.d(i,{R:()=>o,x:()=>a});var s=n(6540);const t={},r=s.createContext(t);function o(e){const i=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function a(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),s.createElement(r.Provider,{value:i},e.children)}}}]);